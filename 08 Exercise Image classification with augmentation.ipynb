{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Image classification with augmentation (10 points)\n",
    "\n",
    "The goal of this example is to explain the organization, import and preparation of image data for classification including augmentation of the images. The following steps are performed:\n",
    "\n",
    "- Dynamic loading and unpacking of image data from an external source.\n",
    "- Review of the organization on the file system\n",
    "- Loading of the data\n",
    "- Transformations\n",
    "- Augmentation\n",
    "- Training\n",
    "- Analysis\n",
    "- Enhancement\n",
    "\n",
    "The dataset used is called caltech101[3,4] with 101 classes and 40 to 800 images per class. The images have 200 - 300 pixel resolution in color.\n",
    "\n",
    "Sources for the examples and data:\n",
    "\n",
    "\n",
    "- [1] [https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/](https://machinelearningmastery.com/how-to-develop-a-cnn-from-scratch-for-cifar-10-photo-classification/)\n",
    "- [2] [https://github.com/bhavul/Caltech-101-Object-Classification](https://github.com/bhavul/Caltech-101-Object-Classification)\n",
    "- [3] [http://www.vision.caltech.edu/Image_Datasets/Caltech101/](http://www.vision.caltech.edu/Image_Datasets/Caltech101/)\n",
    "\n",
    "\n",
    "Citation for the Caltech 101 Dataset:\n",
    "\n",
    "```\n",
    "[4] L. Fei-Fei, R. Fergus and P. Perona. Learning generative visual models\n",
    "    from few training examples: an incremental Bayesian approach tested on\n",
    "    101 object categories. IEEE. CVPR 2004, Workshop on Generative-Model\n",
    "    Based Vision. 2004\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Document your results by simply adding a markdown cell or a python cell (as comment) and writing your statements into this cell. For some tasks the result cell is already available.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ditomax/mlexercises/blob/master/08%20Exercise%20Image%20classification%20with%20augmentation.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare colab\n",
    "#\n",
    "import os\n",
    "\n",
    "COLAB=False\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    print(\"running on google colab\")\n",
    "    COLAB=True\n",
    "    os.makedirs('data/caltech101',exist_ok=True)    \n",
    "    os.makedirs('results',exist_ok=True)    \n",
    "except:\n",
    "    print(\"not running on google colab\")\n",
    "\n",
    "\n",
    "#\n",
    "# Turn off errors and warnings (does not work sometimes)\n",
    "#\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n",
    "simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Import of modules\n",
    "#\n",
    "import logging\n",
    "import tarfile\n",
    "import operator\n",
    "import random\n",
    "from urllib.request import urlretrieve\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "#\n",
    "# Tensorflow and Keras\n",
    "#\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, Input, Dropout, Activation, Dense, MaxPooling2D, Flatten, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adadelta\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#\n",
    "# GPU Support\n",
    "#\n",
    "tflogger = tf.get_logger()\n",
    "tflogger.setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print('using GPU support')\n",
    "\n",
    "\n",
    "#\n",
    "# Sizes of plots\n",
    "#\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "\n",
    "\n",
    "#\n",
    "# Versions\n",
    "#\n",
    "print('working on keras version {} on tensorflow {} using sklearn {}'.format ( tf.keras.__version__, tf.version.VERSION, sklearn.__version__ ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support functions for loading of data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "urlDataSource = 'http://www.vision.caltech.edu/Image_Datasets/Caltech101/101_ObjectCategories.tar.gz'\n",
    "localExtractionFolder = 'data/caltech101'\n",
    "localDataArchive = 'data/caltech101/caltech101.tar.gz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load data from URL\n",
    "#\n",
    "def download_dataset(url,dataset_file_path):\n",
    "    if os.path.exists(localDataArchive):\n",
    "        print(\"archive already downloaded.\")\n",
    "    else:\n",
    "        print(\"started loading archive from url {}\".format(url))\n",
    "        filename, headers = urlretrieve(url, dataset_file_path)\n",
    "        print(\"finished loading archive from url {} with filename {}\".format(url,filename))\n",
    "\n",
    "#\n",
    "# Extract images from archive\n",
    "#       \n",
    "def extract_dataset(dataset_file_path, extraction_directory):\n",
    "    if (not os.path.exists(extraction_directory)):\n",
    "        os.makedirs(extraction_directory)\n",
    "    if (dataset_file_path.endswith(\"tar.gz\") or dataset_file_path.endswith(\".tgz\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:gz\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    elif (dataset_file_path.endswith(\"tar\")):\n",
    "        tar = tarfile.open(dataset_file_path, \"r:\")\n",
    "        tar.extractall(path=extraction_directory)\n",
    "        tar.close()\n",
    "    print(\"extraction of dataset from {} to {} done.\".format(dataset_file_path,extraction_directory) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load image data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**\n",
    "\n",
    "The download of the caltech 101 archive does not work any longer from python code. Please download the archive manually from the link above ```urlDataSource``` and paste the archive file at the location and name given in ```localDataArchive```. In colab you can easily add the archive by uploading it. However, note to store it at the correction folder position under the correct name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Run loading functions\n",
    "#\n",
    "download_dataset(urlDataSource,localDataArchive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Extract files\n",
    "#\n",
    "extract_dataset(localDataArchive,localExtractionFolder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Organisation of image data on a file system\n",
    "\n",
    "\n",
    "- [Brownlee](https://machinelearningmastery.com/how-to-load-large-datasets-from-directories-for-deep-learning-with-keras/) \n",
    "- [Sarkar](https://towardsdatascience.com/a-single-function-to-streamline-image-classification-with-keras-bd04f5cfe6df)\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Read both of the above documents and describe the organization of image data in the file system as it is shown in one of the two linked documents (2 points).\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Get images from category folder \n",
    "#\n",
    "def get_images(object_category, data_directory):\n",
    "    if (not os.path.exists(data_directory)):\n",
    "        print(\"data directory not found.\")\n",
    "        return\n",
    "    obj_category_dir = os.path.join(os.path.join(data_directory,\"101_ObjectCategories\"),object_category)\n",
    "    images = [os.path.join(obj_category_dir,img) for img in os.listdir(obj_category_dir)]\n",
    "    return images\n",
    "\n",
    "\n",
    "#\n",
    "# Get categories\n",
    "#\n",
    "def return_categories(data_directory):\n",
    "    folder = os.path.join(data_directory,\"101_ObjectCategories\")\n",
    "    categories=[d for d in os.listdir(folder) if os.path.isdir(os.path.join(folder,d))]\n",
    "    return categories\n",
    "\n",
    "\n",
    "\n",
    "#\n",
    "# Crop to square whitout cutting\n",
    "#\n",
    "def expand2square(pil_img, background_color):\n",
    "    width, height = pil_img.size\n",
    "    if width == height:\n",
    "        return pil_img\n",
    "    elif width > height:\n",
    "        result = Image.new(pil_img.mode, (width, width), background_color)\n",
    "        result.paste(pil_img, (0, (width - height) // 2))\n",
    "        return result\n",
    "    else:\n",
    "        result = Image.new(pil_img.mode, (height, height), background_color)\n",
    "        result.paste(pil_img, ((height - width) // 2, 0))\n",
    "        return result\n",
    "\n",
    "\n",
    "#\n",
    "# Read image into memory\n",
    "#\n",
    "def read_image(image_path):\n",
    "    im = Image.open(image_path).convert(\"RGB\")\n",
    "    im = expand2square(im, (0, 0, 0) )\n",
    "    im = im.resize( (200,200) )\n",
    "    return np.array(im).astype(np.float32)\n",
    "\n",
    "\n",
    "#\n",
    "# Loading images into memory\n",
    "#\n",
    "def create_training_data(data_directory,fraction):\n",
    "    \n",
    "    i = 0\n",
    "    X = []\n",
    "    Y = []\n",
    "    \n",
    "    print(\"started to read dataset from {}.\".format(data_directory) )\n",
    "    \n",
    "    for category in return_categories(data_directory):\n",
    "        \n",
    "        if category == 'BACKGROUND_Google':\n",
    "            continue\n",
    "        \n",
    "        print(\".\",end='')\n",
    "        \n",
    "        for image in get_images(category, data_directory):\n",
    "            if not image.endswith('.jpg'):\n",
    "                continue\n",
    "                \n",
    "            if random.uniform(0, 1) > fraction:\n",
    "                continue\n",
    "                \n",
    "            X.insert(i, read_image(image) )\n",
    "            Y.insert(i, category )\n",
    "            i += 1\n",
    "            \n",
    "    print(\".\")\n",
    "    print(\"finished reading dataset.\")\n",
    "    X = np.array(X)\n",
    "    return X,Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load training data into memory. Collect only a random sample of 70%. Does not care about distribution of classes.\n",
    "#\n",
    "X_raw, Y_raw = create_training_data(localExtractionFolder,fraction=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check shapes of data\n",
    "#\n",
    "print('X shape {}, Y len {}'.format(X_raw.shape,len(Y_raw)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Transformation of labels in one-hot encoding\n",
    "#\n",
    "label_encoder = LabelEncoder()\n",
    "Y_integer_encoded = label_encoder.fit_transform(Y_raw)\n",
    "Y_one_hot = to_categorical(Y_integer_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_integer_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Scale image data\n",
    "#\n",
    "\n",
    "X_normalized = ( X_raw / 256.0 ) + 0.001\n",
    "del X_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Explain why we do a ```del X_raw``` here. (2 points).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Split data into training and validation sets\n",
    "#\n",
    "X_train, X_validation, Y_train, Y_validation = train_test_split(X_normalized, Y_one_hot, test_size=0.25, random_state=42)\n",
    "del X_normalized\n",
    "\n",
    "\n",
    "#\n",
    "# values are now in X_train, X_validation, Y_train, Y_validation, label_encoder, data_directory\n",
    "#"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Shape of final data\n",
    "#\n",
    "print('train: X=%s, y=%s' % (X_train.shape, Y_train.shape))\n",
    "print('test: X=%s, y=%s' % (X_validation.shape, Y_validation.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check the pixel values\n",
    "#\n",
    "np.amax(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.amin(X_train[0])        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot some images\n",
    "#\n",
    "_, axarr = plt.subplots(4,4)\n",
    "for row in range(4):\n",
    "    for column in range(4):\n",
    "        axarr[row,column].imshow(X_train[row*4+column])        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check distribution of classes\n",
    "#\n",
    "df = pd.DataFrame(Y_integer_encoded,columns=['class'])\n",
    "counts= df.groupby('class').size()\n",
    "counts\n",
    "#np.histogram(Y_integer_encoded, bins=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_pos = np.arange(101)\n",
    "plt.bar(class_pos, counts, align='center', alpha=0.5)\n",
    "plt.xlabel(class_pos)\n",
    "plt.ylabel('digits')\n",
    "plt.title('samples per digit')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "The current distribution of classes is not balanced. Research in the internet, what we could do to improve the distribution of classes. Write down and describe two possible solutions (2 points).\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Erzeugen eines einfache Modelles\n",
    "#\n",
    "def createModel():\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3,3), activation='relu', input_shape=(200,200,3)))\n",
    "    model.add(Conv2D(32, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Conv2D(64, (3,3), activation='relu'))\n",
    "    model.add(Conv2D(128, (3,3), activation='relu'))\n",
    "    model.add(MaxPooling2D(pool_size=2, strides=2))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(512, activation='relu'))\n",
    "    model.add(Dense(101, activation='softmax'))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Compile und Training des Modelles\n",
    "#\n",
    "model_cnn = createModel()\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Callbacks steuern das Speichern von Checkpoints und eine Überwachung gegen Overfitting.\n",
    "#\n",
    "callbacks = [ EarlyStopping(monitor='val_loss', patience=4, verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Run the training and try to find out how much memory the training is using. (2 point).\n",
    "\n",
    "**Hint**: look for the memory usage of the python process.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_cnn.fit(X_train, Y_train, batch_size=16, epochs=6, verbose=1, validation_data=(X_validation,Y_validation), callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluation of model quality with validation data\n",
    "#\n",
    "_, acc = model_cnn.evaluate(X_validation, Y_validation, verbose=0)\n",
    "print('accuracy {:.3f} '.format(acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print training loss and accuracy\n",
    "#\n",
    "def summarize_diagnostics(history,modelname):\n",
    "    plt.subplot(211)\n",
    "    plt.title('Cross Entropy Loss')\n",
    "    plt.plot(history.history['loss'], color='blue', label='train')\n",
    "    plt.plot(history.history['val_loss'], color='lightblue', label='test')\n",
    "    plt.subplot(212)\n",
    "    plt.title('Classification Accuracy')\n",
    "    plt.plot(history.history['accuracy'], color='green', label='train')\n",
    "    plt.plot(history.history['val_accuracy'], color='lightgreen', label='test')\n",
    "    plt.subplots_adjust(hspace=0.5)\n",
    "    plt.savefig( 'results/' + modelname + '_plot.png')\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_diagnostics(history,'05_model_cnn')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization using augmentation\n",
    "\n",
    "Augmentation extends the training dataset with artificially generated images. This makes a model more robust and does not refer to individual pixels. Methods of augmentation for images are:\n",
    "\n",
    "- Change width and height of image content (width_shift_range, height_shift_range).\n",
    "- mirroring (flip)\n",
    "- Rotation (rotation_range)\n",
    "- Zooming (zoom_range)\n",
    "- Brightness (brightness_range)\n",
    "- Distortion (shear_range)\n",
    "\n",
    "Adding noise cannot be set directly in Keras using the [ImageDataGenerator](https://keras.io/preprocessing/image/). However, this is approximately simulated by using dropout.\n",
    "\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Experiment with the augmentation settings of the image generator to increase the accuracy by at least 5%. (2 point).\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create generator for image loading\n",
    "#\n",
    "datagen = ImageDataGenerator(...)\n",
    "# prepare iterator\n",
    "it_train = datagen.flow(X_train, Y_train, batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Training\n",
    "#\n",
    "steps = int(X_train.shape[0] / 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_cnn = createModel()\n",
    "model_cnn.compile(loss='categorical_crossentropy',optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model_cnn.fit(it_train, steps_per_epoch=steps, epochs=12, validation_data=(X_validation,Y_validation), verbose=1, callbacks=callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Evaluation\n",
    "#\n",
    "_, acc = model_cnn.evaluate(X_validation, Y_validation, verbose=0)\n",
    "print('accuracy {:.3f} '.format(acc) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize_diagnostics(history,'08_model_cnn_aug')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test your model on a new image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare image (reusing import function defined above)\n",
    "#\n",
    "image_data_1 = np.array(read_image('data/test_image_1.png')) / 255.0\n",
    "image_data_2 = np.array(read_image('data/test_image_2.png')) / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(image_data_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_cnn.predict(np.array([image_data_1,image_data_2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes = np.argmax(prediction,axis=1)\n",
    "predicted_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(label_encoder.inverse_transform ( predicted_classes ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
