{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Import of excel data and timeseries prediction (10 points)\n",
    "\n",
    "The goal of this example is to show the work with time series from Excel files and to develop a prediction model for time series. The data set describes the development of passenger numbers of an airline in the distant past. However, the data is typical for data as found in SME's (e.g. sales figures). \n",
    "\n",
    "\n",
    "The code for this example was adapted from [1]. Further information is available here [2]. \n",
    "\n",
    "- [1] [https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)\n",
    "- [2] [https://towardsdatascience.com/predict-electricity-consumption-using-time-series-analysis-4650284e40aa](https://towardsdatascience.com/predict-electricity-consumption-using-time-series-analysis-4650284e40aa)\n",
    "\n",
    "\n",
    "Citation dataset:\n",
    "```\n",
    "Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control. Third Edition. Holden-Day. Series G.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openpyxl\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "plt.rcParams[\"figure.figsize\"] = (16,9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# handle error messages\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# FÃ¼r GPU Support\n",
    "#\n",
    "import tensorflow as tf\n",
    "print ( tf.__version__ ) \n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "tf.compat.v1.keras.backend.set_session(tf.compat.v1.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelData = 'data/airline_passengers.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data from Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.ExcelFile(excelData)\n",
    "print(data.sheet_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# read one table\n",
    "#\n",
    "df = data.parse('Tabellenblatt1')\n",
    "df.info\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut out data from pandas dataframes\n",
    "\n",
    "Tutorial: [https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/](https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/)\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# cut out data\n",
    "#\n",
    "# Task: cut out the data from the dataframe using the iloc function described above to have \n",
    "# only relevant data left (timestamp and passenger number, no NaNs) (2 points)\n",
    "#\n",
    "\n",
    "df_cut = ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to fixed names\n",
    "df_cut.columns = ['month','passengers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# plot number of passangers\n",
    "#\n",
    "# Task: plot the passenger data from the pandas dataframe (1 point)\n",
    "#\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional methods\n",
    "\n",
    "There are many older methods to work with time series:\n",
    "\n",
    "- https://machinelearningmastery.com/time-series-trends-in-python/\n",
    "- https://towardsdatascience.com/predict-electricity-consumption-using-time-series-analysis-4650284e40aa\n",
    "\n",
    "\n",
    "The main purpose of these methods is the calculation and use of parameters such as **trend** and **seasonality**. We hope that our models can handle them without us having to explicitly deal with them.\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# prepare data\n",
    "#\n",
    "x_data = df_cut['passengers'].values\n",
    "x_data = x_data.astype('float32')\n",
    "x_data = np.reshape(x_data,(-1,1))\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Normalize the dataset\n",
    "#\n",
    "# Task: create a minmax scaler from sklearn to scale the data between 0 and 1 and store the trained scaler in\n",
    "# a python variable called scaler (2 points)\n",
    "#\n",
    "scaler = ...\n",
    "scaler.fit(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# actually scale the data\n",
    "#\n",
    "x_data = scaler.transform(x_data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# split into train and test sets with 80% training data\n",
    "#\n",
    "train_size = int(len(x_data) * 0.80)\n",
    "test_size = len(x_data) - train_size\n",
    "train, test = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# plot scaled training data for check\n",
    "#\n",
    "plt.plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training data set with sliding windows\n",
    "\n",
    "Sliding windows are created from a time series by dragging a window over the entire time series and copying the data in the window. More details here [https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe](https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe).\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create sliding windows with one label (y)\n",
    "#\n",
    "# Task: add comments for the details of this function (1 point)\n",
    "#\n",
    "def createSlidingWindowsWithLabel(dataset, look_back=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-look_back-1):\n",
    "        a = dataset[ i:(i+look_back), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + look_back, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# apply sliding window function with window size (window_length)\n",
    "#\n",
    "window_length = 1\n",
    "trainX, trainY = createSlidingWindowsWithLabel(train, window_length)\n",
    "testX, testY = createSlidingWindowsWithLabel(test, window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# reshape input to be [samples, time steps, features]\n",
    "#\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], window_length, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], window_length, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create and fit the LSTM network\n",
    "#\n",
    "def createLSTMModel():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(6, input_shape=(1, window_length)))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = createLSTMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = lstm_model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(testX, testY), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Estimate values for train and test data\n",
    "#\n",
    "trainPredict = lstm_model.predict(trainX)\n",
    "testPredict = lstm_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Inverse transformation of estimations (scaler)\n",
    "#\n",
    "trainPredicti = scaler.inverse_transform(trainPredict)\n",
    "testPredicti = scaler.inverse_transform(testPredict)\n",
    "\n",
    "trainYi = scaler.inverse_transform([trainY])\n",
    "testYi = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot estimations\n",
    "#\n",
    "plt.plot(testYi[0,0:])\n",
    "plt.plot(testPredicti[1:,0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# calculate root mean squared error\n",
    "#\n",
    "# Task: calculate the root mean squared error between the test labels and the prediction (1 point)\n",
    "# Hint: labels are in testYi[0,0:-1]\n",
    "#       predictions are in testPredicti[1:,0]\n",
    "\n",
    "trainScore = ...\n",
    "print('train loss: %.3f RMSE' % (trainScore))\n",
    "testScore = ...\n",
    "print('test loss: %.3f RMSE' % (testScore))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot complete timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(x_data)\n",
    "trainPredictPlot[:, :] = np.nan\n",
    "trainPredictPlot[:len(trainPredicti)+0, :] = trainPredicti\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(x_data)\n",
    "testPredictPlot[:, :] = np.nan\n",
    "testPredictPlot[len(trainPredicti)+(look_back*2):len(x_data)-2, :] = testPredicti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot baseline and predictions\n",
    "plt.plot(scaler.inverse_transform(x_data), color='grey')\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment with different window and model sizes (3 points)\n",
    "\n",
    "**change request**: The customer wants a better prediction quality. Conduct an experiment with a different window_length. Another option is to increase the capacity of the model. Compare the resulting RMSE values. \n",
    "Hopefully, this increases the quality of the prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# apply sliding window function with window size (window_length)\n",
    "#\n",
    "window_length = ?\n",
    "trainX, trainY = createSlidingWindowsWithLabel(train, window_length)\n",
    "testX, testY = createSlidingWindowsWithLabel(test, window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check shape of windows\n",
    "print(trainX.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
