{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Classification of IRIS flowers (10 points)\n",
    "\n",
    "The goal of the exercise is to estimate the species of an iris flower using 4 features. For this we use \n",
    "different classification methods.\n",
    "We use a data set by Edgar Anderson or R. Fischer from 1936 [1][2]. The dataset contains 150 samples, each with\n",
    "4 measured values petal length, petal width, sepal length, sepal width as features and the correct class as label.  \n",
    "\n",
    "```\n",
    "[1] Edgar Anderson (1936). \"The species problem in Iris\". Annals of the Missouri Botanical Garden. 23 (3): 457–509. doi:10.2307/2394164. JSTOR 2394164.\n",
    "[2] R. A. Fisher, “The use of multiple measurements in taxonomic problems,” Ann. Eugen., vol. 7, no. 2, pp. 179–188, 1936.\n",
    "```\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Document your results by simply adding a markdown cell or a python cell (as comment) and writing your statements into this cell. For some tasks the result cell is already available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import numpy as np\n",
    "from pandas.plotting import scatter_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n",
    "plt.rcParams['figure.figsize'] = [16, 9]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading and checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Load data\n",
    "# \n",
    "names = ['sepal-length', 'sepal-width', 'petal-length', 'petal-width', 'class']\n",
    "df = pandas.read_csv('data/iris/iris.csv', names=names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Basic data check\n",
    "#\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check the distribution of the classes\n",
    "# Task: implement your own code to print the distribution of classes in this dataset (1 point)\n",
    "#\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Separate the dataset into training data and test data\n",
    "#\n",
    "array = df.values\n",
    "X = array[:,0:4]\n",
    "Y = array[:,4]\n",
    "validation_size = 0.40\n",
    "X_train, X_validation, Y_train, Y_validation = model_selection.train_test_split(X, Y, test_size=validation_size, random_state=42)\n",
    "\n",
    "# Task: search the internet for the description of the train_test_split function (2 points)\n",
    "# and describe the used parameters.\n",
    "# find out what stratification means\n",
    "# change the split to 70% training data and 30% test data\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train a simple classifier using the kNN method\n",
    "#\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=5,metric='euclidean')\n",
    "knn_classifier.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Calculate the accuracy of the trained model\n",
    "#\n",
    "predictions = knn_classifier.predict(X_validation)\n",
    "print('Accuracy: {}'.format(accuracy_score(Y_validation, predictions)))\n",
    "#\n",
    "# Task: search the internet for a concise description of the accuracy quality measure. (1 point)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print a confusion matrix\n",
    "#\n",
    "# Task: search the internet for a description of the confusion matrix and write it down here. (1 point)\n",
    "print(confusion_matrix(Y_validation, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test of a second method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train another classifier using the decision tree method\n",
    "# \n",
    "# Task: implement a decision tree classifier for the IRIS dataset (2 points)\n",
    "# test with accuracy_score using Y_validation\n",
    "#\n",
    "\n",
    "# your code here\n",
    "tree_classifier = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Calculate accuracy\n",
    "#\n",
    "predictions = tree_classifier.predict(X_validation)\n",
    "print('Accuracy: {}'.format(accuracy_score(Y_validation, predictions)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing multiple methods at the same time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'\n",
    "\n",
    "models = []\n",
    "models.append(('KNN', KNeighborsClassifier(n_neighbors=5)))\n",
    "models.append(('CART', DecisionTreeClassifier()))\n",
    "models.append(('NB', GaussianNB()))\n",
    "models.append(('SVM', SVC(gamma='auto')))\n",
    "\n",
    "results = []\n",
    "names = []\n",
    "for name, model in models:\n",
    "    kfold = model_selection.KFold(n_splits=5, random_state=42,shuffle=True)\n",
    "    cv_results = model_selection.cross_val_score(model, X, Y, cv=kfold, scoring=scoring)\n",
    "    results.append(cv_results)\n",
    "    names.append(name)\n",
    "    print(\"Modell {}: accuracy {:.3f} (deviation {:.3f})\".format(name, cv_results.mean(), cv_results.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Algorithm Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "positions = range(len(names))\n",
    "ax.set_xticks(np.arange(0, len(names)))\n",
    "plt.violinplot(results,positions)\n",
    "ax.set_xticklabels(names)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing one method with hyperparameter optimization\n",
    "\n",
    "The idea of hyperparameter optimization is to test several variations of hyperparameters and select those parameters which produce the best quality (accuracy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task: implement a hyperparameter search for the hyperparameter n_neighbors \n",
    "# of the KNeighborsClassifier and document the best result. (3 points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring = 'accuracy'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "parameters = []\n",
    "\n",
    "# your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Algorithms\n",
    "fig = plt.figure()\n",
    "fig.suptitle('n_neighbors Comparison')\n",
    "ax = fig.add_subplot(111)\n",
    "positions = range(len(parameters))\n",
    "ax.set_xticks(np.arange(0, len(parameters)))\n",
    "plt.violinplot(results,positions)\n",
    "ax.set_xticklabels(parameters)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
