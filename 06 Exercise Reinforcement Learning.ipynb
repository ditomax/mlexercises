{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise: Reinforcement Learning Moon Lander (10 points)\n",
    "\n",
    "\n",
    "The goal of this exercise is to work with reinforcement learning models and get a basic understanding of the topic. We will first develop controlers for the simple cart pole model and later for the lunar lander.\n",
    "Neil Armstrong was the first to control a lunar lander in 1969. See a [video](https://youtu.be/xc1SzgGhMKc?t=520) about this masterpiece.\n",
    "Luckily, we do not have to go to the moon, but can do our experiments in simulation based on the [Openai gym](https://gym.openai.com/) software.\n",
    "\n",
    "\n",
    "**NOTE**: if openai gym does not install in anaconda, please install the following packages **in your conda environment** using the following commands:\n",
    "\n",
    "```\n",
    "conda install swig\n",
    "pip install gym\n",
    "pip install box2d-py\n",
    "pip install pyglet\n",
    "```\n",
    "\n",
    "**NOTE**: it can happend that the rendering window does not show up or close properly. In this case please check your environment and look for a solution and post it in the forum.\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Document your results by simply adding a markdown cell or a python cell (as comment) and writing your statements into this cell. For some tasks the result cell is already available.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ditomax/mlexercises/blob/master/06%20Exercise%20Reinforcement%20Learning.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not running on google colab\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Prepare colab\n",
    "#\n",
    "COLAB=False\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    print(\"running on google colab\")\n",
    "    COLAB=True\n",
    "    !pip install gym\n",
    "    !pip install box2d-py\n",
    "    !sudo apt-get install -y xvfb ffmpeg x11-utils\n",
    "    !pip install -q 'imageio==2.4.0'\n",
    "    !pip install -q PILLOW\n",
    "    !pip install -q 'pyglet==1.3.2'\n",
    "    !pip install -q pyvirtualdisplay\n",
    "    \n",
    "except:\n",
    "    print(\"not running on google colab\")\n",
    "\n",
    "\n",
    "#\n",
    "# Turn off errors and warnings (does not work sometimes)\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "#\n",
    "# Import modules\n",
    "#\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    import PIL.Image\n",
    "    import pyvirtualdisplay\n",
    "    # Set up a virtual display for rendering OpenAI gym environments.\n",
    "    display = pyvirtualdisplay.Display(visible=0, size=(1400, 900)).start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Some print options for numpy\n",
    "#\n",
    "np.set_printoptions(precision=4)\n",
    "np.set_printoptions(suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting notebook with tensorflow version 2.4.1\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Tensorflow\n",
    "#\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "\n",
    "\n",
    "#\n",
    "# Check version\n",
    "#\n",
    "print('starting notebook with tensorflow version {}'.format(tf.version.VERSION))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Control system with random controller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Run this basic cart pole example with a randome controller (env.action_space.sample()) (2 point) \n",
    "\n",
    "Find out how the example works and what the basic functions of gym are. \n",
    "\n",
    "Comment **each line** of the code with python comments. \n",
    "\n",
    "Find out what the *observation* and *action* values for the cart-pole mean and how the reward is generated.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " pos:-0.06 pole angle:0.02 reward:1.0 cr:4.0 d:False   a:1 restarts:5       \n",
      "longest run 28 with 5 restarts\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Result: comments in code\n",
    "#\n",
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "cumulated_reward = 0\n",
    "restart_count = 0\n",
    "longest_run = 0\n",
    "cycle_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    if not COLAB:\n",
    "        env.render(mode='close')\n",
    "    \n",
    "    action = env.action_space.sample()\n",
    "\n",
    "    observation, reward, done, info = env.step( action )\n",
    "    \n",
    "    cumulated_reward += reward\n",
    "    cycle_count += 1\n",
    "    \n",
    "    print( '\\r', 'pos:{:.2f} pole angle:{:.2f} reward:{} cr:{} d:{}   a:{} restarts:{}     '.format(observation[2],observation[0],reward,cumulated_reward,done,action, restart_count), end='' )\n",
    "    \n",
    "    if done:\n",
    "        env.reset()\n",
    "        cumulated_reward = 0\n",
    "        longest_run = max(longest_run,cycle_count)\n",
    "        cycle_count = 0\n",
    "        restart_count += 1\n",
    "        \n",
    "    # some delay for display to catch up\n",
    "    time.sleep(0.05)\n",
    "      \n",
    "env.close()\n",
    "\n",
    "print( '\\nlongest run {} with {} restarts'.format( longest_run, restart_count) )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic on-off control strategy \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Lets attempt to control the cart pole with a simple on-off control strategy. (2 Points)\n",
    "    \n",
    "Reading the [documentation](https://github.com/openai/gym/wiki/CartPole-v0) of this gym we find that it has two actions (push cart left = 0 and push cart right = 1). \n",
    "    \n",
    "So, one idea could be to just look at the pole's angle and push the cart left if the pole leans to the left and vice versa. Give it a try.\n",
    "    \n",
    "**Note:** the angle of the pole is negative if the pole is right from the center.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " position:-0.07 pole angle:0.03 r:1.0 cr:100.0 d:False   a:1   \n",
      "longest run 11 with 10 restarts\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v0')\n",
    "env.reset()\n",
    "\n",
    "cumulated_reward = 0\n",
    "pole_angle = 0\n",
    "last_action = -1\n",
    "\n",
    "restart_count = 0\n",
    "longest_run = 0\n",
    "cycle_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "\n",
    "    if not COLAB:\n",
    "        env.render(mode='close')\n",
    "    \n",
    "    #\n",
    "    # action values: 0 push cart to the left, 1 push cart to the right\n",
    "    \n",
    "    # TASK: implement your control strategy here\n",
    "    \n",
    "    if ...:\n",
    "        action = 1\n",
    "    else:\n",
    "        action = 0\n",
    "\n",
    "    observation, reward, done, info = env.step( action )\n",
    "    cumulated_reward += reward\n",
    "\n",
    "    pole_angle = observation[0]\n",
    "    cycle_count += 1\n",
    "    last_action = action\n",
    "\n",
    "        \n",
    "    print( '\\r', 'position:{:.2f} pole angle:{:.2f} r:{} cr:{} d:{}   a:{}   '.format(observation[2],observation[0],reward,cumulated_reward,done,action), end='' )\n",
    "    \n",
    "    if done:\n",
    "        env.reset()\n",
    "        cululated_reward = 0\n",
    "        longest_run = max(longest_run,cycle_count)\n",
    "        cycle_count = 0\n",
    "        restart_count += 1\n",
    "\n",
    "    # some delay important for display to catch up\n",
    "    time.sleep(0.05)\n",
    "      \n",
    "env.close()\n",
    "\n",
    "print( '\\nlongest run {} with {} restarts'.format( longest_run, restart_count) )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Controller \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Now lets build a first version based on advanced RL technique, the Deep Q-Network. \n",
    "    \n",
    "http://arxiv.org/pdf/1312.5602.pdf\n",
    "\n",
    "http://arxiv.org/abs/1509.06461\n",
    "\n",
    "    \n",
    "With DQN, a neural network is trained to estimate the best action for a state based on the Q-learning concept.\n",
    "\n",
    "The code is based on the work by Greg Surma and it can be found [here](https://github.com/gsurma/cartpole).\n",
    "\n",
    "Please go through the code and answer the questions in the comments of the code (marked by TASK). (2 Points)\n",
    "\n",
    "**Note**: Place your answer as comment below the questions.\n",
    "\n",
    "**Note**: This implementation of the DQN does not completely correspond to commonly used DQN implementations. It contains some artistic extensions :-)    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "from collections import deque\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.models import model_from_json\n",
    "\n",
    "prefix = 'results/04_dqn_'\n",
    "\n",
    "# sources:\n",
    "# hyperparameters from https://towardsdatascience.com/ai-learning-to-land-a-rocket-reinforcement-learning-84d61f97d055\n",
    "# further info from https://towardsdatascience.com/deep-q-learning-tutorial-mindqn-2a4c855abffc\n",
    "\n",
    "\n",
    "GAMMA = 0.8\n",
    "#LEARNING_RATE = 0.00025\n",
    "LEARNING_RATE = 0.007\n",
    "MEMORY_SIZE = 1000000\n",
    "BATCH_SIZE = 20\n",
    "EXPLORATION_MAX = 0.70\n",
    "EXPLORATION_MIN = 0.1\n",
    "EXPLORATION_DECAY = 0.97\n",
    "\n",
    "class DQNControl:\n",
    "\n",
    "    def __init__(self, observation_space, action_space,layout=[24,24],name='nona'):\n",
    "        \n",
    "        print ('building DQN model with observation space {} and action space {} layer {} name {}'.format(observation_space, action_space,layout,name) )\n",
    "        \n",
    "        self.exploration_rate = EXPLORATION_MAX\n",
    "        self.action_space = action_space\n",
    "        \n",
    "        #\n",
    "        # TASK: what is the function of a deque?\n",
    "        # ...\n",
    "        self.memory = deque(maxlen=MEMORY_SIZE)\n",
    "        self.name = name\n",
    "        \n",
    "        init = tf.keras.initializers.HeUniform()\n",
    "        self.model = Sequential()\n",
    "        self.model.add(Dense(layout[0], input_shape=(observation_space,), activation=\"relu\", kernel_initializer=init ))\n",
    "        self.model.add(Dense(layout[1], activation=\"relu\", kernel_initializer=init))\n",
    "        self.model.add(Dense(self.action_space, activation=\"linear\", kernel_initializer=init))\n",
    "        self.model.compile(loss=tf.keras.losses.Huber(), optimizer=Adam( learning_rate=LEARNING_RATE, clipnorm=1.0 ))\n",
    "\n",
    "        \n",
    "    def save(self):\n",
    "        modelName = prefix + self.name + \"model.json\"\n",
    "        weightName = prefix + self.name + \"model.h5\"\n",
    "        model_json = self.model.to_json()\n",
    "        with open( modelName , \"w\") as json_file:\n",
    "            json_file.write(model_json)\n",
    "        # serialize weights to HDF5\n",
    "        self.model.save_weights( weightName )\n",
    "        print(\"saved model to disk as {} {}\".format(modelName,weightName))\n",
    "\n",
    "        \n",
    "    def load(self):    \n",
    "        modelName = prefix + self.name + \"model.json\"\n",
    "        weightName = prefix + self.name + \"model.h5\"\n",
    "        json_file = open(modelName, 'r')\n",
    "        loaded_model_json = json_file.read()\n",
    "        json_file.close()\n",
    "        self.model = model_from_json(loaded_model_json)\n",
    "        self.model.load_weights(weightName)\n",
    "        print(\"loaded model from disk file {} {}\".format(modelName,weightName) )\n",
    "        \n",
    "        \n",
    "    def remember(self, state, action, reward, next_state, done):\n",
    "        self.memory.append((state, action, reward, next_state, done))\n",
    "        \n",
    "        \n",
    "    def action(self,state):\n",
    "        # delivers the prediction for the Q function (best action for the state)\n",
    "        q_values = self.model.predict(state)\n",
    "        #\n",
    "        # TASK: what is the idea behind this step (argmax of q_values)?\n",
    "        # ....\n",
    "        #\n",
    "        return np.argmax(q_values[0])\n",
    "        \n",
    "        \n",
    "    def act(self, state):\n",
    "        # delivers either a random action OR\n",
    "        # TASK: what is the purpose of this if statement\n",
    "        # ....\n",
    "        #\n",
    "        if np.random.rand() < self.exploration_rate:\n",
    "            return random.randrange(self.action_space)\n",
    "\n",
    "        return self.action(state)\n",
    "\n",
    "    \n",
    "    def experience_replay(self):\n",
    "        \n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        \n",
    "        batch = random.sample(self.memory, BATCH_SIZE)\n",
    "        \n",
    "        # build a training patch with all batch samples\n",
    "        batch_state = []\n",
    "        batch_q_values = []\n",
    "        for state, action, reward, state_next, done in batch:\n",
    "            q_value_update = reward\n",
    "            if not done:\n",
    "                #\n",
    "                # TASK: give an explanation for the formula of the update of the Q-value\n",
    "                # ...\n",
    "                #\n",
    "                q_value_update = reward + ( GAMMA * np.amax( self.model.predict(state_next)[0] ) ) \n",
    "            \n",
    "            q_values = self.model.predict(state)\n",
    "            \n",
    "            q_values[0][action] = q_value_update\n",
    "            batch_state.append(state[0])\n",
    "            batch_q_values.append(q_values[0])\n",
    "        \n",
    "        x= np.array(batch_state)    \n",
    "        y= np.array(batch_q_values)    \n",
    "        \n",
    "        self.model.fit(x, y, epochs=1, verbose=0)\n",
    "            \n",
    "            \n",
    "    def close_episode(self):\n",
    "        #\n",
    "        # TASK: what is going on here?\n",
    "        # ...\n",
    "        #\n",
    "        self.exploration_rate *= EXPLORATION_DECAY\n",
    "        self.exploration_rate = max(EXPLORATION_MIN, self.exploration_rate)\n",
    "        \n",
    "\n",
    "\n",
    "def trainDQN(env,episodes=50,layout=[24,24], name='nona', termination_reward=None, termination_runs=None, termination_runs_reward=None ):\n",
    "    \n",
    "    observation_space = env.observation_space.shape[0]\n",
    "    action_space = env.action_space.n\n",
    "\n",
    "    dqn_solver = DQNControl(observation_space, action_space,layout,name)\n",
    "    \n",
    "    history = []\n",
    "    run = 0\n",
    "    \n",
    "    accumulated_reward = 0\n",
    "    sliding_accumulated_reward = 0\n",
    "    \n",
    "    while run < episodes:\n",
    "        \n",
    "        state = env.reset()\n",
    "        state = np.reshape(state, [1, observation_space])\n",
    "        step = 0\n",
    "        while True:\n",
    "            \n",
    "            step += 1\n",
    "            \n",
    "            if not COLAB:\n",
    "                env.render(mode='close')\n",
    "            \n",
    "            action = dqn_solver.act(state)\n",
    "            \n",
    "            state_next, reward, terminal, info = env.step(action)\n",
    "            \n",
    "            accumulated_reward += reward\n",
    "            \n",
    "            if not (termination_runs is None) and step > termination_runs:\n",
    "                terminal = True\n",
    "                if not (termination_runs_reward is None):\n",
    "                    reward = termination_runs_reward\n",
    "            else:\n",
    "                if terminal and not (termination_reward is None):\n",
    "                    reward = termination_reward\n",
    "            \n",
    "            state_next = np.reshape(state_next, [1, observation_space])\n",
    "            \n",
    "            dqn_solver.remember(state, action, reward, state_next, terminal)\n",
    "            \n",
    "            state = state_next\n",
    "            \n",
    "            if terminal:\n",
    "                \n",
    "                sliding_accumulated_reward = sliding_accumulated_reward * 0.9 + accumulated_reward * 0.1\n",
    "                \n",
    "                print ( '\\r', 'episode: {}, exploration: {:.3f}, score: {} sliding score {}'.format(run,dqn_solver.exploration_rate,accumulated_reward,sliding_accumulated_reward), end='' )\n",
    "                \n",
    "                history.append([run,dqn_solver.exploration_rate,accumulated_reward,sliding_accumulated_reward,step])\n",
    "                \n",
    "                accumulated_reward = 0\n",
    "                break\n",
    "            \n",
    "            dqn_solver.experience_replay()\n",
    "        \n",
    "        \n",
    "        dqn_solver.close_episode()\n",
    "        \n",
    "        \n",
    "        run += 1\n",
    "\n",
    "    env.close()\n",
    "    return dqn_solver,history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create new environment\n",
    "#\n",
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building DQN model with observation space 4 and action space 2 layer [24, 24] name cartdqn\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 12:38:17.777921: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-16 12:38:18.338761: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n",
      "2021-11-16 12:38:18.356406: I tensorflow/core/platform/profile_utils/cpu_utils.cc:112] CPU Frequency: 4050060000 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " episode: 49, exploration: 0.157, score: 101.0 sliding score 69.607620628899556"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Train model using trainDQN function\n",
    "#\n",
    "control,history = trainDQN(env=env,episodes=50,layout=[24,24],name='cartdqn',termination_reward=-300,termination_runs=100,termination_runs_reward=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "saved model to disk as results/04_dqn_cartdqnmodel.json results/04_dqn_cartdqnmodel.h5\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "# Save model for later\n",
    "#\n",
    "control.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create dataframe from history\n",
    "#\n",
    "df = pd.DataFrame(history,columns=['run','exploration_rate','accumulated_reward','sliding_accumulated_reward','step'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['exploration_rate'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['accumulated_reward'].plot()\n",
    "df['sliding_accumulated_reward'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test the DQL control\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building DQN model with observation space 4 and action space 2 layer [24, 24] name cartdqn\n",
      "loaded model from disk file results/04_dqn_cartdqnmodel.json results/04_dqn_cartdqnmodel.h5\n",
      " position:0.09 pole angle:0.07 reward:1.0 cumulated reward:41.0 d:False   a:1     \n",
      "longest run 59 with 1 restarts\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('CartPole-v1')\n",
    "\n",
    "env.reset()\n",
    "\n",
    "observation_space = env.observation_space.shape[0]\n",
    "action_space = env.action_space.n\n",
    "\n",
    "control = DQNControl(observation_space, action_space, name='cartdqn')\n",
    "control.load()\n",
    "\n",
    "state = env.reset()\n",
    "cumulated_reward = 0\n",
    "restart_count = 0\n",
    "longest_run = 0\n",
    "cycle_count = 0\n",
    "\n",
    "for i in range(100):\n",
    "    \n",
    "    if not COLAB:\n",
    "        env.render(mode='close')\n",
    "\n",
    "    # get the next action from the controler\n",
    "    action = control.action( np.reshape(state, [1, observation_space] ) )\n",
    "    \n",
    "    # apply action to environment\n",
    "    observation, reward, done, _ = env.step( action )\n",
    "    \n",
    "    # check status\n",
    "    cumulated_reward += reward\n",
    "    cycle_count += 1\n",
    "    state = observation\n",
    "        \n",
    "    print( '\\r', 'position:{:.2f} pole angle:{:.2f} reward:{} cumulated reward:{} d:{}   a:{}    '.format(observation[2],observation[0],reward,cumulated_reward,done, action), end='' )\n",
    "    \n",
    "    if done:\n",
    "        state = env.reset()\n",
    "        cumulated_reward = 0\n",
    "        longest_run = max(longest_run,cycle_count)\n",
    "        cycle_count = 0\n",
    "        restart_count += 1\n",
    "\n",
    "    # some delay important for display to catch up\n",
    "    time.sleep(0.05)\n",
    "      \n",
    "env.close()\n",
    "\n",
    "print( '\\nlongest run {} with {} restarts'.format( longest_run, restart_count) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lunar lander problem\n",
    "\n",
    "How we are looking into the lunar lander problem. We reuse the DQN controller from above with different parameters. Play with this problem and get an understanding of the rewards. Configuration is taken from [2]. A general discussion about this approach was published in [1].\n",
    "\n",
    "- [1] https://www.researchgate.net/publication/333145451_Deep_Q-Learning_on_Lunar_Lander_Game\n",
    "- [2] https://towardsdatascience.com/ai-learning-to-land-a-rocket-reinforcement-learning-84d61f97d055"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create new environment for lunar lander\n",
    "#\n",
    "env = gym.make('LunarLander-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building DQN model with observation space 8 and action space 4 layer [64, 32] name lunar\n",
      " episode: 19, exploration: 0.392, score: -107.77132835349899 sliding score -43.347043827655985"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_22636/2370863606.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcontrol\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainDQN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepisodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlayout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lunar'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtermination_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtermination_runs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtermination_runs_reward\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_22636/4109915839.py\u001b[0m in \u001b[0;36mtrainDQN\u001b[0;34m(env, episodes, layout, name, termination_reward, termination_runs, termination_runs_reward)\u001b[0m\n\u001b[1;32m    189\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m             \u001b[0mdqn_solver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_replay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_22636/4109915839.py\u001b[0m in \u001b[0;36mexperience_replay\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    110\u001b[0m                 \u001b[0;31m# ...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;31m#\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m                 \u001b[0mq_value_update\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreward\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mGAMMA\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mamax\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate_next\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0mq_values\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                         '. Consider setting it to AutoShardPolicy.DATA.')\n\u001b[1;32m   1597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m       data_handler = data_adapter.DataHandler(\n\u001b[0m\u001b[1;32m   1599\u001b[0m           \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model, steps_per_execution)\u001b[0m\n\u001b[1;32m   1098\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m     \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m     self._adapter = adapter_cls(\n\u001b[0m\u001b[1;32m   1101\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m         \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    317\u001b[0m     \u001b[0;31m# trigger the next permutation. On the other hand, too many simultaneous\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m     \u001b[0;31m# shuffles can contend on a hardware level and degrade all performance.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     \u001b[0mindices_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpermutation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprefetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mslice_batch_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, map_func, num_parallel_calls, deterministic)\u001b[0m\n\u001b[1;32m   1803\u001b[0m     \"\"\"\n\u001b[1;32m   1804\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mnum_parallel_calls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1805\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mMapDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1806\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1807\u001b[0m       return ParallelMapDataset(\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, input_dataset, map_func, use_inter_op_parallelism, preserve_cardinality, use_legacy_function)\u001b[0m\n\u001b[1;32m   4201\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_use_inter_op_parallelism\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0muse_inter_op_parallelism\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4202\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_preserve_cardinality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpreserve_cardinality\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4203\u001b[0;31m     self._map_func = StructuredFunctionWrapper(\n\u001b[0m\u001b[1;32m   4204\u001b[0m         \u001b[0mmap_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_transformation_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, func, transformation_name, dataset, input_classes, input_shapes, input_types, input_structure, add_to_graph, use_legacy_function, defun_kwargs)\u001b[0m\n\u001b[1;32m   3523\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtracking\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresource_tracker_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_tracker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3524\u001b[0m         \u001b[0;31m# TODO(b/141462134): Switch to using garbage collection.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3525\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapper_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_concrete_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3526\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0madd_to_graph\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3527\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mget_concrete_function\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3049\u001b[0m       \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0minputs\u001b[0m \u001b[0mto\u001b[0m \u001b[0mspecialize\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3050\u001b[0m     \"\"\"\n\u001b[0;32m-> 3051\u001b[0;31m     graph_function = self._get_concrete_function_garbage_collected(\n\u001b[0m\u001b[1;32m   3052\u001b[0m         *args, **kwargs)\n\u001b[1;32m   3053\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_garbage_collector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_get_concrete_function_garbage_collected\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3017\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3018\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3019\u001b[0;31m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3020\u001b[0m       \u001b[0mseen_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3021\u001b[0m       captured = object_identity.ObjectIdentitySet(\n",
      "\u001b[0;32m~/anaconda3/envs/ml/lib/python3.9/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3360\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmissed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcall_context_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3361\u001b[0m           \u001b[0mgraph_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_graph_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3362\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprimary\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3364\u001b[0m           \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "control,history = trainDQN(env=env,episodes=150,layout=[64,32],name='lunar',termination_reward=None,termination_runs=150,termination_runs_reward=-200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model for later\n",
    "control.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[1].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[2].plot()\n",
    "df[3].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "\n",
    "Implement an improved controler for the lunar lander (4 points) \n",
    "\n",
    "Search the internet for leadboards for lunar lander and try to implement one of the best solutions. Select your solution by simplicity and clarity of code. Comment the code.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Result: implementation of improved controler\n",
    "#\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
