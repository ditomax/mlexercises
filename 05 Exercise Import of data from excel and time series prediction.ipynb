{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Import of excel data and timeseries prediction (10 points)\n",
    "\n",
    "The goal of this example is to show the work with time series from Excel files and to develop a prediction model for time series. The data set describes the development of passenger numbers of an airline in the distant past. However, the data is typical for data as found in SME's (e.g. sales figures). \n",
    "\n",
    "\n",
    "The code for this example was adapted from [1]. Further information on classical time series prediction is available here [2]. \n",
    "\n",
    "- [1] [https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/](https://machinelearningmastery.com/time-series-prediction-lstm-recurrent-neural-networks-python-keras/)\n",
    "- [2] [https://www.kdnuggets.com/2020/01/predict-electricity-consumption-time-series-analysis.html](https://www.kdnuggets.com/2020/01/predict-electricity-consumption-time-series-analysis.html)\n",
    "\n",
    "\n",
    "Citation dataset:\n",
    "```\n",
    "Box, G. E. P., Jenkins, G. M. and Reinsel, G. C. (1976) Time Series Analysis, Forecasting and Control. Third Edition. Holden-Day. Series G.\n",
    "```\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Document your results by simply adding a markdown cell or a python cell (as comment) and writing your statements into this cell. For some tasks the result cell is already available.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ditomax/mlexercises/blob/master/05%20Exercise%20Import%20of%20data%20from%20excel%20and%20time%20series%20prediction.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import of modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare colab\n",
    "#\n",
    "import os\n",
    "\n",
    "COLAB=False\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    print(\"running on google colab\")\n",
    "    COLAB=True\n",
    "    os.makedirs('data/caltech101',exist_ok=True)    \n",
    "    os.makedirs('results',exist_ok=True)    \n",
    "except:\n",
    "    print(\"not running on google colab\")\n",
    "\n",
    "\n",
    "#\n",
    "# Turn off errors and warnings (does not work sometimes)\n",
    "#\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n",
    "simplefilter(action='ignore', category=RuntimeWarning)\n",
    "\n",
    "\n",
    "\n",
    "import os\n",
    "import logging\n",
    "import openpyxl\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import LSTM\n",
    "\n",
    "#\n",
    "# GPU Support\n",
    "#\n",
    "tflogger = tf.get_logger()\n",
    "tflogger.setLevel(logging.ERROR)\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR )\n",
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "    print('using GPU support')\n",
    "\n",
    "\n",
    "#\n",
    "# Sizes of plots\n",
    "#\n",
    "plt.rcParams['figure.figsize'] = [16, 9]\n",
    "\n",
    "\n",
    "#\n",
    "# Versions\n",
    "#\n",
    "print('working on keras version {} on tensorflow {} using sklearn {} numpy {}'.format ( tf.keras.__version__, tf.version.VERSION, sklearn.__version__, np.__version__ ) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excelData = 'data/airline_passengers.xlsx'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the data from Excel file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if COLAB:\n",
    "    base_url = 'https://raw.githubusercontent.com/ditomax/mlexercises/master/'\n",
    "    df = pd.read_excel(base_url + excelData, engine = 'openpyxl')\n",
    "else:\n",
    "    df = pd.read_excel(excelData, engine = 'openpyxl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# read one table\n",
    "#\n",
    "df.info\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cut out data from pandas dataframes\n",
    "\n",
    "Tutorial: [https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/](https://www.shanelynn.ie/select-pandas-dataframe-rows-and-columns-using-iloc-loc-and-ix/)\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Cut out the data from the dataframe using the iloc function described above to have \n",
    "only relevant data left (timestamp and passenger number, no NaNs) (2 points)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to fixed names\n",
    "df_cut.columns = ['month','passengers']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cut.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Plot the passenger data from the pandas dataframe in a 2D plot (1 point)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conventional methods\n",
    "\n",
    "There are many older methods to work with time series:\n",
    "\n",
    "- https://machinelearningmastery.com/time-series-trends-in-python/\n",
    "- https://www.kdnuggets.com/2020/01/predict-electricity-consumption-time-series-analysis.html\n",
    "\n",
    "\n",
    "The main purpose of these methods is the calculation and use of parameters such as **trend** and **seasonality**. We hope that our models can handle them without us having to explicitly deal with them.\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = df_cut['passengers'].values\n",
    "x_data = x_data.astype('float32')\n",
    "x_data = np.reshape(x_data,(-1,1))\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Scale the dataset. Create a minmax scaler from sklearn to scale the data \n",
    "between 0 and 1 and store the trained scaler in a python variable called scaler (2 points)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = ...\n",
    "scaler.fit(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(scaler.data_max_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# actually scale the data\n",
    "#\n",
    "x_data = scaler.transform(x_data)\n",
    "print(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# split into train and test sets with 80% training data\n",
    "#\n",
    "train_size = int(len(x_data) * 0.80)\n",
    "test_size = len(x_data) - train_size\n",
    "train, test = x_data[0:train_size,:], x_data[train_size:len(x_data),:]\n",
    "print(len(train), len(test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# plot scaled training data for check\n",
    "#\n",
    "plt.plot(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create a training data set with sliding windows\n",
    "\n",
    "Sliding windows are created from a time series by dragging a window over the entire time series and copying the data in the window. More details here [https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe](https://towardsdatascience.com/ml-approaches-for-time-series-4d44722e48fe).\n",
    "\n",
    "<img src=\"info.png\" align=\"left\"/> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 2\n",
    "window_length = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Create sliding windows with one label with the function `createSlidingWindowsWithLabel`.\n",
    "Add comments for the details of this function (1 point)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Create sliding window data sets.\n",
    "#\n",
    "def createSlidingWindowsWithLabel(dataset, window_length=1):\n",
    "    dataX, dataY = [], []\n",
    "    for i in range(len(dataset)-window_length-1):\n",
    "        a = dataset[ i:(i+window_length), 0]\n",
    "        dataX.append(a)\n",
    "        dataY.append(dataset[i + window_length, 0])\n",
    "    return np.array(dataX), np.array(dataY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# apply sliding window function with window size (window_length)\n",
    "#\n",
    "trainX, trainY = createSlidingWindowsWithLabel(train, window_length)\n",
    "testX, testY = createSlidingWindowsWithLabel(test, window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# reshape input to be [samples, time steps, features]\n",
    "#\n",
    "trainX = np.reshape(trainX, (trainX.shape[0], window_length, trainX.shape[1]))\n",
    "testX = np.reshape(testX, (testX.shape[0], window_length, testX.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create an LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "epochs = 100\n",
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create and fit the LSTM network\n",
    "#\n",
    "def createLSTMModel():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(6, input_shape=(window_length,1)))\n",
    "    model.add(Dense(1,activation='linear'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model = createLSTMModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "history = lstm_model.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=1, validation_data=(testX, testY), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot history\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Estimate values for train and test data\n",
    "#\n",
    "trainPredict = lstm_model.predict(trainX)\n",
    "testPredict = lstm_model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Inverse transformation of estimations (scaler)\n",
    "#\n",
    "trainPredicti = scaler.inverse_transform(trainPredict)\n",
    "trainPredicti = np.reshape(trainPredicti, (-1,))\n",
    "\n",
    "testPredicti = scaler.inverse_transform(testPredict)\n",
    "testPredicti = np.reshape(testPredicti, (-1,))\n",
    "\n",
    "\n",
    "trainYi = scaler.inverse_transform([trainY])\n",
    "trainYi = np.reshape(trainYi, (-1,))\n",
    "\n",
    "testYi = scaler.inverse_transform([testY])\n",
    "testYi = np.reshape(testYi, (-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Plot estimations\n",
    "#\n",
    "plt.plot(testYi[0:])\n",
    "plt.plot(testPredicti[0:], linestyle='dashed')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Calculate the root mean squared error between the test labels and the prediction (1 point)\n",
    "\n",
    "Hint: labels are in testYi[0,0:-1] and predictions are in testPredicti[1:,0]\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# calculate root mean squared error\n",
    "#\n",
    "\n",
    "trainScore = ...\n",
    "print('train loss: {:.3f} RMSE (passengers)'.format(trainScore))\n",
    "\n",
    "testScore = ...\n",
    "print('test loss: {:.3f} RMSE (passengers)'.format(testScore))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot complete timeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shift train predictions for plotting\n",
    "trainPredictPlot = np.empty_like(x_data_scaled)\n",
    "trainPredictPlot[:] = np.nan\n",
    "trainPredictPlot[window_length:len(trainPredicti)+window_length] = trainPredicti\n",
    "\n",
    "# shift test predictions for plotting\n",
    "testPredictPlot = np.empty_like(x_data_scaled)\n",
    "testPredictPlot[:] = np.nan\n",
    "testPredictPlot[len(trainPredicti)+(window_length*2):len(x_data)] = testPredicti\n",
    "\n",
    "# plot baseline and predictions\n",
    "plt.plot( x_data, color='grey', linestyle='dashed')\n",
    "plt.plot(trainPredictPlot)\n",
    "plt.plot(testPredictPlot)\n",
    "plt.axvline(x=window_length, linestyle='dotted')\n",
    "plt.axvline(x=len(trainPredicti)+window_length, linestyle='dotted')\n",
    "plt.axvline(x=len(trainPredicti)+2*window_length, linestyle='dotted')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "It seems that the model only learns to use the last feature value as the prediction value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Increase the prediction quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "We want to have a better prediction quality. Conduct several experiments with different values for **window_length**, the **capacity of the model** and the **batch size** of the training. Compare the resulting RMSE values. \n",
    "Hopefully, this increases the quality of the prediction. (3 Points)\n",
    "\n",
    "**Hint**: maybe you pack the code below into a function ...\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results\n",
    "\n",
    "Please document your results here:\n",
    "\n",
    "| Test score | window_length | batch size | model size |\n",
    "|----------|:---------------:|-----------:|-----------:|\n",
    "| 54.432   |  1            |  12         | 20          |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Hyperparameters\n",
    "#\n",
    "window_length = 1\n",
    "batch_size = 12\n",
    "model_size = 20\n",
    "epochs = 300\n",
    "dropout = 0.001\n",
    "learning_rate = 0.0005"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# apply sliding window function with window size (window_length)\n",
    "#\n",
    "trainX, trainY = createSlidingWindowsWithLabel(train, window_length)\n",
    "testX, testY = createSlidingWindowsWithLabel(test, window_length)\n",
    "fullX, fullY = createSlidingWindowsWithLabel(full, window_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# reshape input to be [samples, time steps, features]\n",
    "#\n",
    "trainX = np.reshape(trainX, (-1, window_length, 1))\n",
    "testX = np.reshape(testX, (-1, window_length, 1))\n",
    "fullX = np.reshape(fullX, (-1, window_length, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# create and fit the LSTM network\n",
    "#\n",
    "def createLSTMModel2():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(model_size, input_shape= (window_length, 1), stateful=False, dropout=dropout ))\n",
    "    model.add(Dense(model_size, activation='relu'))\n",
    "    model.add(Dense(1, activation='linear'))\n",
    "    opt = Adam( learning_rate=learning_rate )\n",
    "    model.compile(loss='mean_squared_error', optimizer=opt )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_model2 = createLSTMModel2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = lstm_model2.fit(trainX, trainY, epochs=epochs, batch_size=batch_size, verbose=0, validation_data=(testX, testY), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Estimate values for train and test data\n",
    "#\n",
    "trainPredict = lstm_model2.predict(trainX)\n",
    "testPredict = lstm_model2.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Inverse transformation of estimations (scaler)\n",
    "#\n",
    "trainPredicti = scaler.inverse_transform(trainPredict)\n",
    "testPredicti = scaler.inverse_transform(testPredict)\n",
    "\n",
    "trainYi = scaler.inverse_transform([trainY])\n",
    "testYi = scaler.inverse_transform([testY])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# calculate root mean squared error\n",
    "#\n",
    "trainScore = math.sqrt(mean_squared_error(trainYi[0,0:-1], trainPredicti[1:,0]))\n",
    "print('train loss: %.3f RMSE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(testYi[0,0:-1], testPredicti[1:,0]))\n",
    "print('test loss: %.3f RMSE' % (testScore))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
