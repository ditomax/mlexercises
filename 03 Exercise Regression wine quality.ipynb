{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"header.png\" align=\"left\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Regression of Wine Quality\n",
    "\n",
    "The aim of the example is to estimate the quality of a wine from physical measurands. To do this, we use different types of regression.\n",
    "We use a dataset of wines from Portugal created by Paulo Cortez [1]. The details of the creation of the data can be found at the following link. [http://www3.dsi.uminho.pt/pcortez/wine5.pdf](http://www3.dsi.uminho.pt/pcortez/wine5.pdf). \n",
    "\n",
    "```\n",
    "[1] P. Cortez, A. Cerdeira, F. Almeida, T. Matos and J. Reis. \n",
    "  Modeling wine preferences by data mining from physicochemical properties.\n",
    "  In Decision Support Systems, Elsevier, 47(4):547-553. ISSN: 0167-9236.\n",
    "```\n",
    "\n",
    "**NOTE**\n",
    "\n",
    "Document your results by simply adding a markdown cell or a python cell (as comment) and writing your statements into this cell. For some tasks the result cell is already available.\n",
    "\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/ditomax/mlexercises/blob/master/03%20Exercise%20Regression%20wine%20quality.ipynb)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import of python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Prepare colab\n",
    "#\n",
    "COLAB=False\n",
    "try:\n",
    "    %tensorflow_version 2.x\n",
    "    print(\"running on google colab\")\n",
    "    COLAB=True\n",
    "except:\n",
    "    print(\"not running on google colab\")\n",
    "\n",
    "#\n",
    "# Turn of some warnings\n",
    "#\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "simplefilter(action='ignore', category=Warning)\n",
    "\n",
    "#\n",
    "# Import modules\n",
    "#\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.linear_model import LinearRegression \n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn import metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Load data from a CSV file. The feature separator is a ';'\n",
    "#\n",
    "\n",
    "\n",
    "if COLAB:\n",
    "    df = pd.read_csv('https://raw.githubusercontent.com/ditomax/mlexercises/master/data/winequality/winequality-red.csv', sep=';')\n",
    "else:\n",
    "    df = pd.read_csv('data/winequality/winequality-red.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Show dimensions of the dataframe\n",
    "#\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Print the first 20 records for checking (1 point)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# your code here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Print also the last records for checking.\n",
    "#\n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Labels are stored in y_complete, x_complete contains only the features. \n",
    "# Drop removes a column if axis=1\n",
    "#\n",
    "y_complete = df['quality']\n",
    "x_complete = df.drop(['quality'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Search the internet for the description of Dataframe.drop in pandas and give a short description here (1 point)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# your description here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check labels\n",
    "#\n",
    "y_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check features\n",
    "#\n",
    "x_complete.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Split data into training and test data\n",
    "#\n",
    "# Note this special feature of python to assign many variables from the return values of a function\n",
    "#\n",
    "x_train, x_test, y_train, y_test = train_test_split ( x_complete, y_complete, train_size=0.8, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check shape of training data\n",
    "#\n",
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Setup a model for linear regression\n",
    "#\n",
    "regressor = LinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Train (fit) the model with training features and training labels\n",
    "#\n",
    "regressor.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check the resulting parameters of the model\n",
    "#\n",
    "print(regressor.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Explain the values in regressor.coef_ . How can we intuitively understand those parameters? (4 points)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# your description here\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Run the model with training and test data and store the results\n",
    "#\n",
    "prediction_train = regressor.predict(x_train)\n",
    "prediction_test = regressor.predict(x_test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Check the prediction results\n",
    "#\n",
    "prediction_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "# Measure the quality of the model estimation on the test data\n",
    "# Using root mean sqare\n",
    "#\n",
    "print('test  root mean squared error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, prediction_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Measure the quality of the model estimation on the training data\n",
    "#\n",
    "print('train root mean squared error: {}'.format(np.sqrt(metrics.mean_squared_error(y_train, prediction_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Using mean absolute error and mean squared error\n",
    "#\n",
    "print('test mean absolute error:     {}'.format(metrics.mean_absolute_error(y_test, prediction_test)))\n",
    "print('test mean squared error:      {}'.format(metrics.mean_squared_error(y_test, prediction_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Support function for counting usable predictions\n",
    "# Note: continuous regression result has to be rounded to categorical quality class (label)\n",
    "#\n",
    "def countAccuracy(prediction,y):\n",
    "    prediction_quality_test = np.round_(prediction)\n",
    "    y_test_data = y.values\n",
    "\n",
    "    correct, incorrect = 0,0\n",
    "    for index in range(prediction_test.shape[0]):\n",
    "        if prediction_quality_test[index] == y_test_data[index]:\n",
    "            correct= correct + 1\n",
    "        else:\n",
    "            incorrect= incorrect + 1\n",
    "\n",
    "    print('count accuracy: {:.4f}'.format((correct/(correct+incorrect))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Use function to measure accuracy of test data prediction\n",
    "#\n",
    "countAccuracy(prediction_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Use function to measure accuracy of training data prediction\n",
    "#\n",
    "countAccuracy(prediction_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a Random Forest Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Implement a new regressor model using the class RandomForestRegressor (2 points)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_regressor = ...\n",
    "random_regressor.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict and measure quality\n",
    "#\n",
    "prediction_train = random_regressor.predict(x_train)\n",
    "prediction_test = random_regressor.predict(x_test) \n",
    "\n",
    "print('test  root mean squared error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, prediction_test))))\n",
    "print('train root mean squared error: {}'.format(np.sqrt(metrics.mean_squared_error(y_train, prediction_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Count accuracy\n",
    "#\n",
    "countAccuracy(prediction_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Is there a way to measure the quality in a more relaxed way?\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# New function for measuring accuracy in a more relaxed way\n",
    "#\n",
    "def countAccuracyRelaxed(prediction,y):\n",
    "    prediction_quality_test = np.round_(prediction)\n",
    "    y_test_data = y.values\n",
    "\n",
    "    correct, incorrect = 0,0\n",
    "    for index in range(prediction_test.shape[0]):\n",
    "        if prediction_quality_test[index] == y_test_data[index]:\n",
    "            correct= correct + 1\n",
    "        elif prediction_quality_test[index] == y_test_data[index] + 1: \n",
    "            correct= correct + 1\n",
    "        elif prediction_quality_test[index] == y_test_data[index] - 1:\n",
    "            correct= correct + 1\n",
    "        else:\n",
    "            incorrect= incorrect + 1\n",
    "\n",
    "    print('count accuracy relaxed: {:.4f}'.format((correct/(correct+incorrect))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Test new measurement\n",
    "#\n",
    "countAccuracyRelaxed(prediction_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test a Neuronal Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "## Task\n",
    "    \n",
    "Experiment with a neural network for regression. Use MLPRegressor class for this task. (2 points)\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Build a neural network regressor (using MLPRegressor)\n",
    "#\n",
    "nn_regressor = ...\n",
    "nn_regressor.fit(x_train, y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Predict and measure quality\n",
    "#\n",
    "prediction_train = nn_regressor.predict(x_train)\n",
    "prediction_test = nn_regressor.predict(x_test) \n",
    "\n",
    "print('test  root mean squared error: {}'.format(np.sqrt(metrics.mean_squared_error(y_test, prediction_test))))\n",
    "print('train root mean squared error: {}'.format(np.sqrt(metrics.mean_squared_error(y_train, prediction_train))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Measure quality\n",
    "#\n",
    "countAccuracy(prediction_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "# Measure quality relaxed\n",
    "#\n",
    "countAccuracyRelaxed(prediction_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
